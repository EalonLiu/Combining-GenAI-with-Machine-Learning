{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenAI Application: Hidden Features Recognition in Facial Expressions\n",
    "## Yilong Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Literature Review\n",
    "To begin, it is essential to review existing literature exploring the relationship between specific facial features and socially relevant outcomes, such as decisions involving the death penalty or electoral success.\n",
    "\n",
    "#### Key Studies\n",
    "\n",
    "A thorough literature review has identified several influential studies pertinent to this research:\n",
    "\n",
    "(1). Todorov et al. (2005) – Electoral Success\n",
    "\n",
    "(2). Jaeger et al. (2020) – Electoral Success\n",
    "\n",
    "(3). Wilson & Rule (2015) – Criminal Sentencing\n",
    "\n",
    "(4). Eberhardt et al. (2006) – Criminal Sentencing and Race\n",
    "\n",
    "(5). Columbia University Study (2023) – Jurors' Sentencing Bias\n",
    "\n",
    "(6). Mueller & Mazur (1996) – Military Leadership (West Point Cadets)\n",
    "\n",
    "#### Experimental Methodology\n",
    "\n",
    "Among these studies, the first three papers, along with the fifth, involved experimental designs in which participants evaluated photographs of individuals. For example, Wilson and Rule (2015) required participants to rate photographs of convicted criminals who had received either the death penalty or life imprisonment.\n",
    "\n",
    "#### Analysis of Specific Facial Features\n",
    "\n",
    "Notably, the fourth and sixth studies provided detailed analyses of specific facial features, including:\n",
    "\n",
    "(1). Skin tone\n",
    "\n",
    "(2). Lip fullness\n",
    "\n",
    "(3). Nose width\n",
    "\n",
    "(4). Jawline strength\n",
    "\n",
    "(5). Brow prominence\n",
    "\n",
    "(6). Facial width-to-height ratio\n",
    "\n",
    "#### Significant Findings\n",
    "\n",
    "Eberhardt et al. (2006): Defendants with more stereotypically Afrocentric facial characteristics, such as darker skin tones and broader noses, received harsher criminal sentences, notably the death penalty. This underscores racial biases in judicial decision-making.\n",
    "\n",
    "Mueller and Mazur (1996): Facial indicators of dominance, such as pronounced jawlines, prominent eyebrows, and higher facial width-to-height ratios, strongly predicted leadership attainment among West Point cadets, highlighting the significant influence of facial cues on professional advancement.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Collectively, these studies underscore the substantial impact facial attributes can have on social perceptions, judgments, and outcomes. Recognizing implicit biases associated with physical appearance is critical when examining decision-making and success in social and organizational contexts.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Coding Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Prepare and import necessary libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import ollama\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor,BlipForConditionalGeneration \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set up a function to get image file paths from a directory.\n",
    "def get_image_path(directory):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    return [os.path.join(directory, file) for file in os.listdir(directory) if file.lower().endswith(tuple(valid_extensions))]\n",
    "\n",
    "# Step 2: Intialize BLIP image captioning model to describe images.\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def caption_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n",
    "        return \"\"\n",
    "    inputs = processor(image, return_tensors = \"pt\")\n",
    "    output_ids = caption_model.generate(**inputs)\n",
    "    caption = processor.decode(output_ids[0], skip_special_tokens = True)\n",
    "    print(f\"Caption for {image_path}:{caption}\")\n",
    "    return caption\n",
    "\n",
    "# Step 3: Extrac facial features using an LLM from Ollama\n",
    "def extract_facial_features(image_path):\n",
    "    default_features = {\n",
    "        \"facial_expression\": None,\n",
    "        \"face_shape\": None,\n",
    "        \"beard_presence\": False,\n",
    "        \"lip_fullness\": None,\n",
    "        \"nose_width\": None,\n",
    "        \"jawline_strength\": None,\n",
    "        \"brow_prominence\": None,\n",
    "        \"facial_width_to_height_ratio\": 0.0\n",
    "    }\n",
    "     \n",
    "    caption = caption_image(image_path)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in facial analysis analyzing portrait of 18th century British naval officers.Based on the following portrait description, extract the facial features intoa JSON object with the following keys:\n",
    "- facial_expression (e.g., \"serious\", \"smiling\", \"neutral\")\n",
    "- face_shape (e.g., \"oval\", \"round\", \"square\")\n",
    "- beard_presence (boolean: true or false)\n",
    "- lip_fullness (e.g., \"thin\", \"average\", \"full\")\n",
    "- nose_width (e.g., \"narrow\", \"average\", \"strong\")\n",
    "- jawline_strength (e.g., \"weak\", \"average\", \"strong\")\n",
    "- brow_prominence (e.g., \"subtle\", \"prominent\")\n",
    "- facial_width_to_height_ratio (a float value)\n",
    "\n",
    "Portrait description: \"{caption}\"\n",
    "\n",
    "Respond with only the JSON object, and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.generate(model = 'llama3', prompt = prompt)\n",
    "    raw_response = response.get('response','').strip()\n",
    "\n",
    "\n",
    "    try:\n",
    "        features = json.loads(raw_response)\n",
    "    except Exception as e:\n",
    "        features = {}\n",
    "\n",
    "    for key, default in default_features.items():\n",
    "        if key not in features or features[key] is None:\n",
    "            features[key] = default\n",
    "    \n",
    "    if isinstance(features['beard_presence'], bool):\n",
    "        features['board_presence'] = int(features['beard_presence'])\n",
    "    return features\n",
    "\n",
    "# Step 4: Build the complete dataset\n",
    "def build_dataset(success_dir, failure_dir, max_workers = 8):\n",
    "    data = []\n",
    "    all_paths = [(path,1) for path in get_image_path(success_dir)]+[(path,0) for path in get_image_path(failure_dir)]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers = max_workers) as executor:\n",
    "        future_to_info = {executor.submit(extract_facial_features, path): (path, label) for path, label in all_paths}\n",
    "        for future in concurrent.futures.as_completed(future_to_info):\n",
    "            path, label = future_to_info[future]\n",
    "            try:\n",
    "                feats = future.result()\n",
    "                feats['label'] = label\n",
    "                data.append(feats)\n",
    "            except Exception as exc:\n",
    "                print(f\"Image {path} generated an exception: {exc}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Step 5: Preprocess the dataset.\n",
    "def preprocess_dataset(df):\n",
    "    if \"beard_presence\" in df.columns:\n",
    "        df['beard_presence'] = df['beard_presence'].apply(lambda x: int(x) if isinstance(x, bool) or x is not None else 0)\n",
    "\n",
    "    categorical_cols = [\n",
    "        'facial_expression', 'face_shape',\n",
    "        'lip_fullness', 'nose_width', \n",
    "        'jawline_strength', 'brow_prominence'\n",
    "    ]\n",
    "    df = pd.get_dummies(df, columns = categorical_cols, dummy_na = True)\n",
    "    X = df.drop(columns = ['label'])\n",
    "    y = df['label']\n",
    "    return X,y\n",
    "\n",
    "# Step 6: Perform Bootstrapping to estimate feature importance.\n",
    "def bootstrap_feature_importance(X,y, B=100, test_size = 0.2):\n",
    "    feature_coef = {col: [] for col in X.columns}\n",
    "    for b in range(B):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = test_size, random_state = np.random.randint(0,10000))\n",
    "        model = LogisticRegression(max_iter = 1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        coefs = model.coef_[0]\n",
    "        for col, coef in zip(X.columns, coefs):\n",
    "            feature_coef[col].append(coef)\n",
    "\n",
    "        feature_importance = {}\n",
    "        for col, coef_list in feature_coef.items():\n",
    "            feature_importance[col] = {\n",
    "                \"mean_coef\": np.mean(coef_list),\n",
    "                \"std_coef\": np.std(coef_list)\n",
    "            }\n",
    "\n",
    "        return feature_importance\n",
    "\n",
    "# Step 7: Select features based on a threshold.    \n",
    "def select_features_split(feature_importance, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Split features into two groups:\n",
    "      - Selected features: those with absolute mean coefficient >= threshold.\n",
    "      - Remaining features: the rest.\n",
    "    \"\"\"\n",
    "    selected = {}\n",
    "    remaining = {}\n",
    "    for feature, stats in feature_importance.items():\n",
    "        if abs(stats[\"mean_coef\"]) >= threshold:\n",
    "            selected[feature] = stats\n",
    "        else:\n",
    "            remaining[feature] = stats\n",
    "    return selected, remaining\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Run the complete pipeline\n",
    "success_dir = \"success-spur/features/imgs/successful\"\n",
    "failure_dir = \"success-spur/features/imgs/unsuccessful\"\n",
    "\n",
    "df = build_dataset(success_dir, failure_dir)\n",
    "print('Data built with shape:', df.shape)\n",
    "\n",
    "X, y = preprocess_dataset(df)\n",
    "\n",
    "\n",
    "B=100\n",
    "feature_importance = bootstrap_feature_importance(X,y,B=B)\n",
    "print(\"Estimated feature importance (all features):\")\n",
    "\n",
    "for feature, stats in feature_importance.items():\n",
    "    print(f\"{feature}: Mean Coefficient = {stats['mean_coef']:.3f}, Std= {stats['std_coef']:.3f}\")\n",
    "\n",
    "threshold = 0.1\n",
    "selected_features, remaining_features = select_features_split(feature_importance, threshold = threshold)\n",
    "\n",
    "print(\"\\nSelected features (|mean_coef| >= {:.2f}):\".format(threshold))\n",
    "for feature, stats in selected_features.items():\n",
    "    print(f\"{feature}: Mean Coefficient = {stats['mean_coef']:.3f}, Std = {stats['std_coef']:.3f}\")\n",
    "\n",
    "print(\"\\nRemaining features (|mean_coef| < {:.2f}):\".format(threshold))\n",
    "for feature, stats in remaining_features.items():\n",
    "    print(f\"{feature}: Mean Coefficient = {stats['mean_coef']:.3f}, Std = {stats['std_coef']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Result Analysis\n",
    "#### Data Overview:\n",
    "A bootstrap method and feature selection process were applied to a dataset comprising 50 samples with 10 facial features. These features, selected based on literature analyzing West Point portraits, include facial width-to-height ratio, presence of beard, facial expression, face shape, lip fullness, nose width, jawline strength, and brow prominence. Additionally, dummy variables indicating missing or unclear feature extraction (marked as \"nan\") were included.\n",
    "#### Key Influential Features:\n",
    "(1). Beard Presence / Board Presence：\n",
    "\n",
    "Both “beard_presence” and “board_presence” show very high positive coefficients (0.761). This indicates that, in your sample, having a beard is strongly associated with a higher likelihood of career success.\n",
    "\n",
    "(2). Lip Fullness:\n",
    "\n",
    "The dummy variables for lip fullness show a large contrast: “lip_fullness_average” has a coefficient of +0.496, while “lip_fullness_thin” is -0.496. This suggests that an average lip fullness is linked with success, whereas thin lips are associated with a lower chance.\n",
    "\n",
    "(3). Facial Expression:\n",
    "\n",
    "“facial_expression_neutral” has a positive coefficient (+0.354) and “facial_expression_serious” a negative coefficient (-0.354). This implies that, relative to the reference (or missing) group, a neutral expression may be more favorable than a serious one in predicting success.\n",
    "\n",
    "(4). Eyebrow Prominence:\n",
    "\n",
    "The “brow_prominence_prominent” dummy shows a positive coefficient (+0.328) and “brow_prominence_subtle” a negative coefficient (-0.328). This suggests that prominent eyebrows may be a positive indicator, while subtle eyebrows may be less favorable.\n",
    "\n",
    "(5). Low-Impact Feature:\n",
    "\n",
    "In contrast, features such as facial width-to-height ratio (–0.013), face shape (both “face_shape_oval” and “face_shape_nan” at 0.000), nose width (0.000), and jawline strength (average: –0.037; strong: 0.037) show near-zero coefficients, indicating that these features have little influence on the model’s predictions.\n",
    "#### Feature Selection:\n",
    "Applying a threshold of |mean_coef| ≥ 0.10, the following features were identified as influential:\n",
    "\n",
    "(1). Beard presence\n",
    "\n",
    "(2). Lip fullness (average and thin)\n",
    "\n",
    "(3). Facial expression (neutral and serious)\n",
    "\n",
    "(4). Brow prominence (prominent and subtle)\n",
    "\n",
    "Features such as facial width-to-height ratio, face shape, nose width, and jawline strength were deemed less significant and thus excluded from further consideration.\n",
    "#### Interpretation:\n",
    "The analysis highlights several facial characteristics strongly correlated with perceptions of career success. Beard presence emerges as the most robust predictor, indicating a societal bias associating beards with positive attributes like maturity or authority. The preference for average lip fullness over thin lips might reflect cultural perceptions of balanced or normative facial features as advantageous. Neutral facial expressions appear to convey approachability or composure, in contrast to serious expressions, which might suggest rigidity or less desirable traits. Prominent eyebrows potentially signify dominance or confidence, enhancing perceived leadership qualities.\n",
    "\n",
    "#### Conclusion:\n",
    "Overall, the analysis underscores the significance of specific facial features in influencing career success perceptions, notably beard presence, lip fullness, facial expression, and eyebrow prominence. However, given the subjective nature of facial feature extraction and interpretation, these results should be cautiously interpreted. Future research could further investigate these findings using diverse and larger samples to validate generalizability and understand underlying societal biases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
